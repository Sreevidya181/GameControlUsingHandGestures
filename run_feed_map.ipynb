{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (6.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\B.Sreevidya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# organize imports\n",
    "\n",
    "import cv2\n",
    "#import imutils\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise\n",
    "from keras.models import load_model\n",
    "# from scipy.misc import imresize\n",
    "\n",
    "# global variables\n",
    "bg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_avg(image, accumWeight):\n",
    "    global bg\n",
    "    # initialize the background\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return\n",
    "\n",
    "    # compute weighted average, accumulate it and update the background\n",
    "    cv2.accumulateWeighted(image, bg, accumWeight)\n",
    "\n",
    "\n",
    "def segment(image, threshold=25):\n",
    "    global bg\n",
    "    # find the absolute difference between background and current frame\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    # threshold the diff image so that we get the foreground\n",
    "    thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # get the contours in the thresholded image\n",
    "    (cnts, _) = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # return None, if no contours detected\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        # based on contour area, get the maximum contour which is the hand\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keyboard in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.13.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogui in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.54)\n",
      "Requirement already satisfied: pymsgbox in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyautogui) (1.0.7)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyautogui) (0.1.30)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: mouseinfo in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pyrect in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (10.0.1)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\b.sreevidya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mouseinfo->pyautogui) (1.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\B.Sreevidya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\B.Sreevidya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 98, 118, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 98, 118, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 49, 59, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 49, 59, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 47, 57, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 47, 57, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 23, 28, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 23, 28, 64)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 41216)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               5275776   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5295750 (20.20 MB)\n",
      "Trainable params: 5295558 (20.20 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "[STATUS] please wait! calibrating...\n",
      "[STATUS] calibration successfull...\n",
      "W\n",
      "A\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "Space\n",
      "A\n",
      "S\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "Space\n",
      "Space\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "W\n",
      "W\n",
      "D\n",
      "D\n",
      "W\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "A\n",
      "A\n",
      "A\n",
      "Space\n",
      "W\n",
      "A\n",
      "Space\n",
      "Space\n",
      "A\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "A\n",
      "A\n",
      "A\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "A\n",
      "A\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "A\n",
      "A\n",
      "Space\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "Space\n",
      "Space\n",
      "A\n",
      "Space\n",
      "Space\n",
      "A\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "A\n",
      "Space\n",
      "A\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "D\n",
      "D\n",
      "A\n",
      "Space\n",
      "D\n",
      "D\n",
      "Space\n",
      "D\n",
      "Space\n",
      "Space\n",
      "W\n",
      "D\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "D\n",
      "Space\n",
      "A\n",
      "S\n",
      "A\n",
      "A\n",
      "A\n",
      "S\n",
      "A\n",
      "Space\n",
      "D\n",
      "D\n",
      "Space\n",
      "D\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "A\n",
      "Space\n",
      "D\n",
      "D\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "W\n",
      "A\n",
      "D\n",
      "D\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "Space\n",
      "W\n",
      "D\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "D\n",
      "S\n",
      "S\n",
      "D\n",
      "A\n",
      "A\n",
      "A\n",
      "D\n",
      "D\n",
      "A\n",
      "A\n",
      "A\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "D\n",
      "W\n",
      "D\n",
      "D\n",
      "S\n",
      "D\n",
      "W\n",
      "A\n",
      "A\n",
      "A\n",
      "S\n",
      "A\n",
      "A\n",
      "A\n",
      "S\n",
      "A\n",
      "D\n",
      "D\n",
      "D\n",
      "A\n",
      "Space\n",
      "A\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "Space\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "S\n",
      "A\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "S\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "W\n",
      "S\n",
      "A\n",
      "A\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "Space\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "S\n",
      "W\n",
      "Space\n",
      "A\n",
      "W\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "Space\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "W\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "S\n",
      "W\n",
      "W\n",
      "Space\n",
      "W\n",
      "Space\n",
      "D\n",
      "D\n",
      "A\n",
      "D\n",
      "A\n",
      "A\n",
      "A\n",
      "D\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "Space\n",
      "S\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "W\n",
      "W\n",
      "W\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n"
     ]
    },
    {
     "ename": "FailSafeException",
     "evalue": "PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailSafeException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 120\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m predictedClass \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh Five\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 120\u001b[0m         \u001b[43mpyautogui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpress\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# show the thresholded image\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\B.Sreevidya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyautogui\\__init__.py:593\u001b[0m, in \u001b[0;36m_genericPyAutoGUIChecks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrappedFunction)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 593\u001b[0m     \u001b[43mfailSafeCheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m     returnVal \u001b[38;5;241m=\u001b[39m wrappedFunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    595\u001b[0m     _handlePause(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pause\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\B.Sreevidya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyautogui\\__init__.py:1734\u001b[0m, in \u001b[0;36mfailSafeCheck\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfailSafeCheck\u001b[39m():\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m FAILSAFE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(position()) \u001b[38;5;129;01min\u001b[39;00m FAILSAFE_POINTS:\n\u001b[1;32m-> 1734\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FailSafeException(\n\u001b[0;32m   1735\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1736\u001b[0m         )\n",
      "\u001b[1;31mFailSafeException\u001b[0m: PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# load Model Weights\n",
    "\n",
    "def _load_weights():\n",
    "    try:\n",
    "        model = load_model(\"hand_gesture_recognition.h5\")\n",
    "        print(model.summary())\n",
    "        # print(model.get_weights())\n",
    "        # print(model.optimizer)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "    \n",
    "def getPredictedClass(model):\n",
    "    if model is None:\n",
    "        print(\"Model is not loaded successfully.\")\n",
    "        return None\n",
    "\n",
    "    image = cv2.imread('Temp.png')\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.resize(gray_image, (100, 120))\n",
    "\n",
    "    gray_image = gray_image.reshape(1, 100, 120, 1)\n",
    "\n",
    "    prediction = model.predict_on_batch(gray_image)\n",
    "\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    if predicted_class == 0:\n",
    "        return \"Blank\"\n",
    "    elif predicted_class == 1:\n",
    "        return \"OK\"\n",
    "    elif predicted_class == 2:\n",
    "        return \"Thumbs Up\"\n",
    "    elif predicted_class == 3:\n",
    "        return \"Thumbs Down\"\n",
    "    elif predicted_class == 4:\n",
    "        return \"Punch\"\n",
    "    elif predicted_class == 5:\n",
    "        return \"High Five\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # initialize accumulated weight\n",
    "    accumWeight = 0.5\n",
    "\n",
    "    # get the reference to the webcam\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    fps = int(camera.get(cv2.CAP_PROP_FPS))\n",
    "    # region of interest (ROI) coordinates\n",
    "    top, right, bottom, left = 10, 350, 225, 590\n",
    "    # initialize num of frames\n",
    "    num_frames = 0\n",
    "    # calibration indicator\n",
    "    calibrated = False\n",
    "    model = _load_weights()\n",
    "    k = 0\n",
    "    # keep looping, until interrupted\n",
    "    while (True):\n",
    "        # get the current frame\n",
    "        (grabbed, frame) = camera.read()\n",
    "        # resize the frame\n",
    "        frame = cv2.resize(frame, (700,700))\n",
    "        # flip the frame so that it is not the mirror view\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # clone the frame\n",
    "        clone = frame.copy()\n",
    "        # get the height and width of the frame\n",
    "        (height, width) = frame.shape[:2]\n",
    "        # get the ROI\n",
    "        roi = frame[top:bottom, right:left]\n",
    "        # convert the roi to grayscale and blur it\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "        # to get the background, keep looking till a threshold is reached\n",
    "        # so that our weighted average model gets calibrated\n",
    "        if num_frames < 30:\n",
    "            run_avg(gray, accumWeight)\n",
    "            if num_frames == 1:\n",
    "                print(\"[STATUS] please wait! calibrating...\")\n",
    "            elif num_frames == 29:\n",
    "                print(\"[STATUS] calibration successfull...\")\n",
    "        else:\n",
    "            # segment the hand region\n",
    "            hand = segment(gray)\n",
    "\n",
    "            # check whether hand region is segmented\n",
    "            if hand is not None:\n",
    "                # if yes, unpack the thresholded image and\n",
    "                # segmented region\n",
    "                (thresholded, segmented) = hand\n",
    "\n",
    "                # draw the segmented region and display the frame\n",
    "                cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "\n",
    "                # count the number of fingers\n",
    "                import pyautogui\n",
    "                # fingers = count(thresholded, segmented)\n",
    "                if k % (fps / 6) == 0:\n",
    "                    cv2.imwrite('Temp.png', thresholded)\n",
    "                    predictedClass = getPredictedClass(model)\n",
    "                    cv2.putText(clone, str(predictedClass), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "                    if predictedClass == \"OK\":\n",
    "                        pyautogui.press('A')\n",
    "                        print(\"A\")\n",
    "                    elif predictedClass == \"Thumbs Up\":\n",
    "                        pyautogui.press('S')\n",
    "                        print(\"S\")\n",
    "                    elif predictedClass == \"Thumbs Down\":\n",
    "                        pyautogui.press('W')\n",
    "                        print(\"W\")\n",
    "                    elif predictedClass == \"Punch\":\n",
    "                        pyautogui.press('D')\n",
    "                        print(\"D\")\n",
    "                    elif predictedClass == \"High Five\":\n",
    "                        pyautogui.press('space')\n",
    "                        print(\"Space\")\n",
    "\n",
    "                # show the thresholded image\n",
    "                cv2.imshow(\"Thresholded\", thresholded)\n",
    "                import keyboard\n",
    "\n",
    "                if keyboard.is_pressed('right'):\n",
    "                    print(\"Right key is pressed!\")\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                # show the thresholded image\n",
    "                # cv2.imshow(\"Thesholded\", thresholded)\n",
    "        k = k + 1\n",
    "        # draw the segmented hand\n",
    "        cv2.rectangle(clone, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # increment the number of frames\n",
    "        num_frames += 1\n",
    "\n",
    "        # display the frame with segmented hand\n",
    "        cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "        # observe the keypress by the user\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the user pressed \"q\", then stop looping\n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # free up memory\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
