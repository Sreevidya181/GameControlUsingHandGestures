{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 142\u001b[0m\n\u001b[0;32m    139\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Call the main function\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 90\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m roi \u001b[38;5;241m=\u001b[39m rotated_frame[top:bottom, right:left]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Convert the ROI to grayscale and blur it\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray, (\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# To get the background, keep looking till a threshold is reached\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# so that our running average model gets calibrated\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Global variables\n",
    "bg = None\n",
    "\n",
    "def run_avg(image, aWeight):\n",
    "    global bg\n",
    "    # Initialize the background\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return\n",
    "\n",
    "    # Compute weighted average, accumulate it, and update the background\n",
    "    cv2.accumulateWeighted(image, bg, aWeight)\n",
    "\n",
    "def segment(image, threshold=25):\n",
    "    global bg\n",
    "    # Find the absolute difference between background and current frame\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    # Threshold the diff image so that we get the foreground\n",
    "    thresholded = cv2.threshold(diff,\n",
    "                                threshold,\n",
    "                                255,\n",
    "                                cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Get the contours in the thresholded image\n",
    "    (cnts, _) = cv2.findContours(thresholded.copy(),\n",
    "                                 cv2.RETR_EXTERNAL,\n",
    "                                 cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Return None if no contours detected\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        # Based on contour area, get the maximum contour which is the hand\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)\n",
    "\n",
    "gestures = [\"Blank\", \"Fist\", \"Ok\", \"Palm\", \"ThumbsUp\", \"ThumbsDown\"]\n",
    "dataset_dir = \"Dataset/\"\n",
    "# Get the reference to the webcam\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "def main():\n",
    "    # Initialize weight for running average\n",
    "    aWeight = 0.5\n",
    "\n",
    "    # Region of interest (ROI) coordinates\n",
    "    top, right, bottom, left = 10, 350, 225, 590\n",
    "\n",
    "    # Initialize num of frames\n",
    "    num_frames = 0\n",
    "    image_num = 1\n",
    "\n",
    "    # Loop through different camera angles\n",
    "    for angle in range(0, 360, 15):  # Adjust the step size for different angles\n",
    "        # Set the camera angle\n",
    "        camera.set(0, angle)\n",
    "\n",
    "        # Keep looping until interrupted\n",
    "        while True:\n",
    "            # Get the current frame\n",
    "            (grabbed, frame) = camera.read()\n",
    "            if grabbed:\n",
    "                # Loop through different orientations\n",
    "                for orientation in range(-30, 31, 15):  # Adjust the step size for different orientations\n",
    "                    # Set the orientation\n",
    "                    rotated_frame = imutils.rotate(frame, orientation)\n",
    "\n",
    "                    # Resize the frame\n",
    "                    rotated_frame = imutils.resize(rotated_frame, width=700)\n",
    "\n",
    "                    # Flip the frame so that it is not the mirror view\n",
    "                    rotated_frame = cv2.flip(rotated_frame, 1)\n",
    "\n",
    "                    # Clone the frame\n",
    "                    clone = rotated_frame.copy()\n",
    "\n",
    "                    # Get the height and width of the frame\n",
    "                    (height, width) = rotated_frame.shape[:2]\n",
    "\n",
    "                    # Get the ROI\n",
    "                    roi = rotated_frame[top:bottom, right:left]\n",
    "\n",
    "                    # Convert the ROI to grayscale and blur it\n",
    "                    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "                    # To get the background, keep looking till a threshold is reached\n",
    "                    # so that our running average model gets calibrated\n",
    "                    if num_frames < 30:\n",
    "                        run_avg(gray, aWeight)\n",
    "                    else:\n",
    "                        # Segment the hand region\n",
    "                        hand = segment(gray)\n",
    "\n",
    "                        # Check whether hand region is segmented\n",
    "                        if hand is not None:\n",
    "                            # If yes, unpack the thresholded image and\n",
    "                            # segmented region\n",
    "                            (thresholded, segmented) = hand\n",
    "\n",
    "                            # Draw the segmented region and display the frame\n",
    "                            cv2.drawContours(\n",
    "                                clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "\n",
    "                            # Mention the directory in which you wanna store the images followed by the image name\n",
    "                            output_dir = os.path.join(dataset_dir, f\"{gestures[0]}Test/\")\n",
    "                            output_path = os.path.join(output_dir, f\"{gestures[0]}_{image_num}.png\")\n",
    "                            cv2.imwrite(output_path, thresholded)\n",
    "                            image_num += 1\n",
    "\n",
    "                    # Draw the segmented hand\n",
    "                    cv2.rectangle(clone, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "                    # Increment the number of frames\n",
    "                    num_frames += 1\n",
    "\n",
    "                    # Display the frame with segmented hand\n",
    "                    cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "                    # Observe the keypress by the user\n",
    "                    keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                    # Start recording when 's' key is pressed\n",
    "                    if keypress == ord(\"s\"):\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                print(\"[Warning!] Error input, Please check your (camera or video)\")\n",
    "                break\n",
    "\n",
    "    # Free up memory\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the main function\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
